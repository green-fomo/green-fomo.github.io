
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <!-- CSS  -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
  <link rel="stylesheet" href="static/css/main.css" media="screen,projection">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
</head>

<body>

<!-- <div class="top-strip"></div> -->
<div class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      
      <div class="navbar-header">
        <a class="navbar-brand" href="/"></a>
        <button class="navbar-toggle" type="button" data-toggle="collapse" data-target="#navbar-main">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
      </div>
  
      <div class="navbar-collapse collapse" id="navbar-main">
        <ul class="nav navbar-nav">
          <li><a href="index.html">About</a></li>
          <li><a href="call.html">Call For Papers</a></li>
          <!--<li><a href="accepted.html">Accepted Papers</a></li>-->
          <li><a href="dates.html">Dates</a></li>
          <li><a href="speakers.html">Invited Speakers</a></li>
          <li><a href="program.html">Program</a></li>
          <li><a href="organizers.html">Organizers</a></li>
        </ul>
      </div>
  
    </div>
  </div>

<div class="container">
  <div class="page-content">
      <p><br /></p>

<div class="containerheading">
    <img src="static/img/site/teaser-image.jpg">
</div>
<hr />

<p><br /></p>
<center>
<div class="row" id="speakers">
  <div class="col-xs-12">
    <h2><u>Invited Speakers</u></h2>
  </div>
</div>
</center>

<p><br /></p>

<div class="row">
    <div class="col-md-2">
      <a href="https://www.ranjaykrishna.com/index.html" target="_blank"><img class="people-pic" style="float:left;margin-right:50px;" src="static/img/people/ranjay-krishna-round.png" /></a>
    </div>
    <div class="col-md-10">
      <p>
        <b><a href="https://www.ranjaykrishna.com/index.html">Dr. Ranjay Krishna</a></b> 
        is an Assistant Professor at the Paul G. Allen School of Computer Science & 
        Engineering. His research lies at the intersection of computer vision and human 
        computer interaction. This research has received best paper, outstanding paper, 
        and orals at CVPR, ACL, CSCW, NeurIPS, UIST, and ECCV, and has been reported by 
        Science, Forbes, the Wall Street Journal, and PBS NOVA. His research has been 
        supported by Google, Amazon, Cisco, Toyota Research Institute, NSF, ONR, and 
        Yahoo. He holds a bachelor's degree in Electrical & Computer Engineering and in 
        Computer Science from Cornell University, a master's degree in Computer Science 
        from Stanford University and a Ph.D. in Computer Science from Stanford University.
        His recent works cover instruction tuning for addressing complex visual tasks with 
        low computational budget.
      </p>
    </div>
</div>
<p><br /></p>

<div class="row">
  <div class="col-md-2">
    <a href="https://cpilab.org/" target="_blank"><img class="people-pic" style="float:left;margin-right:50px;" src="static/img/people/eric-schulz-round.png"/></a>
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="https://cpilab.org/">Dr. Eric Schulz</a></b> 
      is an incoming professor at LMU and the director of the Institute of Human Centered 
      AI at Helmholtz Munich. He finished PhD at UCL in 2017 working on generalization and 
      exploration in reinforcement learning. From 2017 to 2019, he was a Data Science 
      Postdoctoral Fellow at Harvard University, where he worked on computational models of 
      learning and decision making and from 2020 to 2023 he was a Max Planck Independent 
      Group Leader at the MPI for Biological Cybernetics. His recent studies on LLMs 
        will bring valuable insights to our workshop from a cognitive perspective.
    </p>
  </div>
</div>
<p><br /></p>


  <div class="row">
    <div class="col-md-2">
      <a href="https://faculty.cc.gatech.edu/~judy/" target="_blank"><img class="people-pic" style="float:left;margin-right:50px;" src="static/img/people/judy-hoffman-round.png" /></a>
    </div>
    <div class="col-md-10">
      <p>
        <b><a href="https://faculty.cc.gatech.edu/~judy/"> Dr. Judy Hoffman</a></b> 
        is assistant Professor in the School of Interactive Computing at Georgia Tech 
        and a member of the Machine Learning Center. Research interests include computer 
        vision, machine learning, domain adaptation, robustness, and fairness. Prior to 
        joining Georgia Tech, Dr. Hoffman was a Visiting Research Scientist at Facebook 
        AI Research and a postdoctoral scholar at Stanford University and UC Berkeley. 
        She received her PhD from UC Berkeley, EECS in 2016 where she was a member of 
        BAIR and BDD. Her recent works focus on FOMO efficiency, e.g. Token Merging (ToMe) and 
        Binary Vision Transformers (BiViT) to reduce the computational burden.
      </p>
    </div>
  </div>

<p><br /></p>

<div class="row">
  <div class="col-md-2">
    <a href="https://stulyakov.com/" target="_blank"><img class="people-pic" style="float:left;margin-right:50px;" src="static/img/people/sergey-tulyakov-round.png" /></a>
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="https://stulyakov.com/"> Dr. Sergey Tulyakov </a></b> is the Director of Research, 
      leading the Creative Vision at Snap Inc. His work focuses on 
      creating methods for manipulating the world via computer vision and machine learning. 
      This includes 2D and 3D methods for photorealistic object manipulation and 
      animation, video synthesis, prediction and retargeting. His work has been published 
      as 30+ top conference papers, journals and patents resulting in multiple 
      tech transfers, including Snapchat Pet Tracking and Real-time Neural Lenses 
      (gender swap, baby face, real-time try-on and many others). His recent work address 
      efficient generation and personalization in the visual domain.</p>
  </div>
</div>

<p><br /></p>

  </body>
</html>